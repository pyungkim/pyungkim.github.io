[
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Generative Art Example: Katharina Brunner\nKatharina Brunner is a generative artist and data journalist whose GitHub repository on Generative Art is a great resource for anyone looking to get started using the programming language R."
  },
  {
    "objectID": "assignment1.html#run-fall.ron-class-github-under-r",
    "href": "assignment1.html#run-fall.ron-class-github-under-r",
    "title": "Assignment 1",
    "section": "2. Run Fall.R(on class GitHub under R)",
    "text": "2. Run Fall.R(on class GitHub under R)\n\na. Give your own colors (e.g. Spring).\n\n\nb. Export the file and post on your GitHub website.\n\n# Title Fall color\n# Credit: https://fronkonstin.com\n\n# Install packages\n# install.packages(\"gsubfn\")\n# install.packages(\"tidyverse\")\nlibrary(gsubfn)\n\nLoading required package: proto\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n# Define elements in plant art\n# Each image corresponds to a different axiom, rules, angle and depth\n\n# Leaf of Fall\n\naxiom=\"X\"\nrules=list(\"X\"=\"F-[[X]+X]+F[+FX]-X\", \"F\"=\"FF\")\nangle=22.5\ndepth=6\n\n\nfor (i in 1:depth) axiom=gsubfn(\".\", rules, axiom)\n\nactions=str_extract_all(axiom, \"\\\\d*\\\\+|\\\\d*\\\\-|F|L|R|\\\\[|\\\\]|\\\\|\") %>% unlist\n\nstatus=data.frame(x=numeric(0), y=numeric(0), alfa=numeric(0))\npoints=data.frame(x1 = 0, y1 = 0, x2 = NA, y2 = NA, alfa=90, depth=1)\n\n\n# Generating data\n# Note: may take a minute or two\n\nfor (action in actions)\n{\n  if (action==\"F\")\n  {\n    x=points[1, \"x1\"]+cos(points[1, \"alfa\"]*(pi/180))\n    y=points[1, \"y1\"]+sin(points[1, \"alfa\"]*(pi/180))\n    points[1,\"x2\"]=x\n    points[1,\"y2\"]=y\n    data.frame(x1 = x, y1 = y, x2 = NA, y2 = NA,\n               alfa=points[1, \"alfa\"],\n               depth=points[1,\"depth\"]) %>% rbind(points)->points\n  }\n  if (action %in% c(\"+\", \"-\")){\n    alfa=points[1, \"alfa\"]\n    points[1, \"alfa\"]=eval(parse(text=paste0(\"alfa\",action, angle)))\n  }\n  if(action==\"[\"){\n    data.frame(x=points[1, \"x1\"], y=points[1, \"y1\"], alfa=points[1, \"alfa\"]) %>%\n      rbind(status) -> status\n    points[1, \"depth\"]=points[1, \"depth\"]+1\n  }\n\n  if(action==\"]\"){\n    depth=points[1, \"depth\"]\n    points[-1,]->points\n    data.frame(x1=status[1, \"x\"], y1=status[1, \"y\"], x2=NA, y2=NA,\n               alfa=status[1, \"alfa\"],\n               depth=depth-1) %>%\n      rbind(points) -> points\n    status[-1,]->status\n  }\n}\n\nggplot() +\n  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2),\n               lineend = \"round\",\n               color=\"red1\", # Set your own Fall color?\n               data=na.omit(points)) +\n  coord_fixed(ratio = 1) +\n  theme_void() # No grid nor axes"
  },
  {
    "objectID": "assignment1.html#write-a-critique-on-a-chart-in-published-work-bookarticlenews-websitehint-learn-from-nathans-example-discussed-in-class",
    "href": "assignment1.html#write-a-critique-on-a-chart-in-published-work-bookarticlenews-websitehint-learn-from-nathans-example-discussed-in-class",
    "title": "Assignment 1",
    "section": "3. Write a critique on a chart in published work (book/article/news website)(Hint: Learn from Nathan’s example discussed in class)",
    "text": "3. Write a critique on a chart in published work (book/article/news website)(Hint: Learn from Nathan’s example discussed in class)\nFigure below indicates the regional destinations of Black and White interstate migrants from non-southern regions for 6 years. In each originating region, the South is a primary destination for both groups. But in each case, Black migrants are more likely to select destinations in the South. This figure shows the trend that Black Americans who moved out of the South returned to the South at a glance. It implies that presidential and congressional election in the South will be more politically competitive.??\n\nBrookings, “A ‘New Great Migration’ is bringing Black Americans back to the South”."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Publication",
    "section": "",
    "text": "Publications in Refereed Journal (In Korean)\n1. Han, M., & Pyung Kim (2022). “Analysis of Factors Affecting Corporate Participation in Carbon Disclosure Project (CDP): Organizational Institutionalism Perspective”. GRI Review, 24(1), 181-209.\n2. Pyung Kim, & Kim, S. (2017). “Analyzing the Opposition to Nuclear Power Energy on the Internet - Focusing on the Moderating Effect of Policy Efficacy”. Crisisonomy, 13(3), 1-15.\n\n\n\n\n\nWork in Progress\n\nPyung Kim, Dohyeong Kim, & Richard Scotch. “Health Inequalities of People with Disability: Barriers and Facilitators for Rehabilitation and Community Re-entry of Burn Injury Survivors” (journal article)\nSarah Maxwell, Chris Brooks,??Pyung Kim, Dohyeon Kim, Connie L. McNeely, & Kevin Thomas. “What Can Hunters Tell Us about Human Tick-Borne Disease Risk? Identifying the Distribution of Tick-Borne Disease in Indiana Counties” (journal article)\nPyung Kim, Seoyong Kim, & Dohyeong Kim. “Think Globally, Act Locally? Role of Global Identity in Tackling Climate Change” (journal article)\nEuel Elliot, Karl Ho, John Eaton, Dohyo Jeong,??Pyung Kim, Sruthi Suresh, & Aishwarya Tyagi “Politics of Culture War: Polarization, Social Media and Public Opinion” (contracted book)"
  },
  {
    "objectID": "assignment3.html",
    "href": "assignment3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "Run a scombe01.R (in classGitHub)\na. Compare the regression models\nFigure 1 shows that the 1st model is relatively linear relationship between x and y. Figure 2 demonstrates that non-linear relationship between x and y. Figure 3 illustrates has outlier that causes bias. x4 in Figure 4 is categorical variable of which lower value has high variance.\n\n# Clear environment\nrm(list=ls())      \n\n## Anscombe (1973) Quartlet\ndata(anscombe)  # Load Anscombe's data\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n# Create four model objects\nlm1 <- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nlm2 <- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nlm3 <- lm(y3 ~ x3, data=anscombe)\nsummary(lm3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nlm4 <- lm(y4 ~ x4, data=anscombe)\nsummary(lm4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\n# Figure 1\nplot(anscombe$x1,anscombe$y1)\nabline(coefficients(lm1))\n\n\n\n# Figure 2\nplot(anscombe$x2,anscombe$y2)\nabline(coefficients(lm2))\n\n\n\n# Figure 3\nplot(anscombe$x3,anscombe$y3)\nabline(coefficients(lm3))\n\n\n\n# Figure 4\nplot(anscombe$x4,anscombe$y4)\nabline(coefficients(lm4))\n\n\n\n\nb.Compare different ways to create the plots(e.g. changing colors, line types, plot characters)\n\n\n## Fancy version (per help file)\nff <- y ~ x\nmods <- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] <- as.name(paste0(\"y\", i))\n  ##      ff[[3]] <- as.name(paste0(\"x\", i))\n  mods[[i]] <- lmi <- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(>F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n# Preparing for the plots\nop <- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"green\", \n       pch = 21, bg = \"blue\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"red\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", \n      outer = TRUE, cex = 1.5)\n\n\n\n\n\nCan you finetune the charts without using other packages (consult RGraphics by Murrell)\n\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"green\", \n       pch = 20, bg = \"yellow\", cex = 1.5,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"red\")\n}\n\n\n\n\n\n\n\n\n\nmtext(\"Anscombe's 4 Regression data sets\", \n      outer = TRUE, cex = 2)\n\n\n\n\n3.How about with ggplot2?(use tidyverse package)\n\nlibrary(ggplot2)\n\n# Figure 1\np1 <- ggplot(anscombe, aes(x1, y1)) +\n  geom_point()\np1 + geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# Figure 2\np2 <- ggplot(anscombe, aes(x2, y2)) +\n  geom_point()\np2 + geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# Figure 3\np3 <- ggplot(anscombe, aes(x3, y3)) +\n  geom_point()\np3 + geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# Figure 4\np4 <- ggplot(anscombe, aes(x4, y4)) +\n  geom_point()\np4 + geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "assignment2.html",
    "href": "assignment2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "## Run Paul Murrell’s RGraphics basic R programs (murrell01.R in GitHub)\na. Be sure to run line byline and note the changes.\nb. Pay attention to the comments and address the question if there is one.\nc. Plotting functions(note: exercise using the happy planet data set http://happyplanetindex.org)\n\n# Clear environment\nrm(list=ls())                          \n\nlibrary(readxl)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(gridBase)\nlibrary(grid)\n\nHPIdata<-read_excel(\"happy-planet-index2019.xlsx\")\npar(mfrow=c(3, 2))\n\n\n# Setting label orientation, margins, and text size\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) \nplot.new()\nplot.window(range(HPIdata$HPI), c(0, 16))\nlines(HPIdata$HPI, HPIdata$Ladder_of_life_Wellbeing)\nlines(HPIdata$HPI, HPIdata$Ecological_Footprint)\npoints(HPIdata$HPI, HPIdata$Ladder_of_life_Wellbeing, \n       pch=16, cex=2) \n\n# Try different cex value?\npoints(HPIdata$HPI, HPIdata$Ecological_Footprint, \n       pch=21, bg=\"white\", cex=2)  \n\n# Different background color\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(20, 65, 5)) \naxis(2, at=seq(0, 10, 2))\naxis(4, at=seq(0, 16, 2))\nbox(bty=\"u\")\nmtext(\"HPI\", side=1, line=2, cex=0.8)\nmtext(\"Ladder of life (Wellbeing)\", \n      side=2, line=2, las=0, cex=0.8)\nmtext(\"Ecological_Footprint\", side=4, line=2, las=0, cex=0.8)\ntext(4, 5, \"Bird 131\")\npar(mar=c(5.1, 4.1, 4.1, 2.1), \n    col=\"black\", fg=\"black\", col.axis=\"black\")\n\n\n\n# Histogram\npar(mar=c(4.5, 4.1, 3.1, 0))\nhist(HPIdata$Ladder_of_life_Wellbeing, breaks=seq(0, 10), \n     ylim=c(0, 0.5), col=\"gray80\", freq=FALSE)\nlines(density(HPIdata$Ladder_of_life_Wellbeing), lwd=2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Boxplot\npar(mar=c(3, 4.1, 2, 0))\n\nboxplot(Ladder_of_life_Wellbeing ~ Continent, data = HPIdata,\n        boxwex = 0.25, at = 1:8 - 0.2,\n        col=\"white\",\n        xlab=\"\",\n        ylab=\"Ladder_of_life_Wellbeing\", ylim=c(0,10))\n\nmtext(\"Continent\", side=1, line=2.5, cex=0.8)\n\npar(mar=c(5.1, 4.1, 4.1, 2.1))  \n\n# Persp\nx <- seq(-10, 10, length= 80)\ny <- x\nf <- function(x,y) { r <- sqrt(x^2+y^2)+7; 10 * tan(r)/r }\nz <- outer(x, y, f)\nz[is.na(z)] <- 1\n\n# 0.5 to include z axis label\npar(mar=c(0, 0.5, 0, 0), lwd=0.5)\npersp(x, y, z, theta = 15, phi = 20, \n      expand = 0.5)\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n# Piechart\npar(mar=c(0, 2, 1, 2), xpd=FALSE, cex=0.5)\npie.sales <- c(0.20, 0.10, 0.30, 0.10, 0.25, 0.05)\nnames(pie.sales) <- c(\"Milk\", \"Water\",\n                      \"Juice\", \"Smoothie\", \"Coffee\", \"Other\")\npie(pie.sales, col = rainbow(6))\n\n# Barplot\n\nHPI1 <- data.frame(HPIdata$Continent, HPIdata$HPI)\n\n\nHPI1 <- transform(HPI1, HPI_grade = ifelse(HPIdata$HPI < 30, \"5\", ifelse(HPIdata$HPI >= 30 & HPIdata$HPI < 40, \"4\", \nifelse(HPIdata$HPI >= 40 & HPIdata$HPI < 50, \"3\", ifelse(HPIdata$HPI >= 50 & HPIdata$HPI < 60, \"2\", \"1\")))))\n\n\nplot.new()              \nvps <- baseViewports()\npushViewport(vps$figure) \nvp1 <-plotViewport(c(0.1,0.1,0,0))\n\np <- ggplot(HPI1, aes(HPIdata.Continent, fill = HPI_grade)) +\n  geom_bar(position=\"stack\")+ theme(legend.title=element_text(size=10), legend.text=element_text(size=10), legend.key.height= unit(0.1, 'cm'))\nprint(p,vp = vp1)\nprint(p,vp = vp1)"
  },
  {
    "objectID": "assignment6.html",
    "href": "assignment6.html",
    "title": "Assignment 6",
    "section": "",
    "text": "require(\"readr\")\n\nLoading required package: readr\n\nrequire(\"shiny\")\n\nLoading required package: shiny\n\nlibrary(\"readxl\")\n\n\n\n# Define UI for dataset viewer app ----\nui <- fluidPage(\n  \n  # App title ----\n  titlePanel(\"Datasets\"),\n  \n  # Sidebar layout with input and output definitions ----\n  sidebarLayout(\n    \n    # Sidebar panel for inputs ----\n    sidebarPanel(\n      \n      # Input: Text for providing a caption ----\n      # Note: Changes made to the caption in the textInput control\n      # are updated in the output area immediately as you type\n      textInput(inputId = \"caption\",\n                label = \"Caption:\",\n                value = \"Datasets\"),\n      \n      # Input: Selector for choosing dataset ----\n      selectInput(inputId = \"dataset\",\n                  label = \"Choose a dataset:\",\n                  choices = c(\"mtcars\", \"USArrests\",\"uspop\", \"pollution\")),\n      \n      # Input: Numeric entry for number of obs to view ----\n      numericInput(inputId = \"obs\",\n                   label = \"Number of observations to view:\",\n                   min=0,\n                   value = 10)\n      \n    ),\n    \n    # Main panel for displaying outputs ----\n    mainPanel(\n      \n      # Output: Formatted text for caption ----\n      h3(textOutput(\"caption\", container = span)),\n      \n      # Output: Verbatim text for data summary ----\n      verbatimTextOutput(\"summary\"),\n      \n      # Output: HTML table with requested number of observations ----\n      tableOutput(\"view\")\n      \n    )\n  )\n)\n\n# Define server logic to summarize and view selected dataset ----\nserver <- function(input, output) {\n  \n  # Return the requested dataset ----\n  # By declaring datasetInput as a reactive expression we ensure\n  # that:\n  #\n  # 1. It is only called when the inputs it depends on changes\n  # 2. The computation and result are shared by all the callers,\n  #    i.e. it only executes a single time\n  datasetInput <- reactive({\n    switch(input$dataset,\n           \"mtcars\" =mtcars,\n           \"USArrests\"=USArrests,\n           \"uspop\"=uspop,\n           \"pollution\"=pollutiondata)\n  })\n  \n  # Create caption ----\n  # The output$caption is computed based on a reactive expression\n  # that returns input$caption. When the user changes the\n  # \"caption\" field:\n  #\n  # 1. This function is automatically called to recompute the output\n  # 2. New caption is pushed back to the browser for re-display\n  #\n  # Note that because the data-oriented reactive expressions\n  # below don't depend on input$caption, those expressions are\n  # NOT called when input$caption changes\n  output$caption <- renderText({\n    input$caption\n  })\n  \n  # Generate a summary of the dataset ----\n  # The output$summary depends on the datasetInput reactive\n  # expression, so will be re-executed whenever datasetInput is\n  # invalidated, i.e. whenever the input$dataset changes\n  output$summary <- renderPrint({\n    dataset <- datasetInput()\n    summary(dataset)\n  })\n  \n  # Show the first \"n\" observations ----\n  # The output$view depends on both the databaseInput reactive\n  # expression and input$obs, so it will be re-executed whenever\n  # input$dataset or input$obs is changed\n  output$view <- renderTable({\n    head(datasetInput(), n = input$obs)\n  })\n  \n}\n\n# Create Shiny app ----\nshinyApp(ui, server)\n\nPhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.\n\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "assignment7.html",
    "href": "assignment7.html",
    "title": "Assignment 7",
    "section": "",
    "text": "rm(list=ls())                          # Clear environment\n\nlibrary(ggplot2)\nlibrary(fmsb)\nlibrary(readxl)\nlibrary(gridBase)\nlibrary(grid)\nlibrary(viridis)\n\nLoading required package: viridisLite\n\nlibrary\n\nfunction (package, help, pos = 2, lib.loc = NULL, character.only = FALSE, \n    logical.return = FALSE, warn.conflicts, quietly = FALSE, \n    verbose = getOption(\"verbose\"), mask.ok, exclude, include.only, \n    attach.required = missing(include.only)) \n{\n    conf.ctrl <- getOption(\"conflicts.policy\")\n    if (is.character(conf.ctrl)) \n        conf.ctrl <- switch(conf.ctrl, strict = list(error = TRUE, \n            warn = FALSE), depends.ok = list(error = TRUE, generics.ok = TRUE, \n            can.mask = c(\"base\", \"methods\", \"utils\", \"grDevices\", \n                \"graphics\", \"stats\"), depends.ok = TRUE), warning(gettextf(\"unknown conflict policy: %s\", \n            sQuote(conf.ctrl)), call. = FALSE, domain = NA))\n    if (!is.list(conf.ctrl)) \n        conf.ctrl <- NULL\n    stopOnConflict <- isTRUE(conf.ctrl$error)\n    if (missing(warn.conflicts)) \n        warn.conflicts <- !isFALSE(conf.ctrl$warn)\n    if (!missing(include.only) && !missing(exclude)) \n        stop(\"only one of 'include.only' and 'exclude' can be used\", \n            call. = FALSE)\n    testRversion <- function(pkgInfo, pkgname, pkgpath) {\n        if (is.null(built <- pkgInfo$Built)) \n            stop(gettextf(\"package %s has not been installed properly\\n\", \n                sQuote(pkgname)), call. = FALSE, domain = NA)\n        R_version_built_under <- as.numeric_version(built$R)\n        if (R_version_built_under < \"3.0.0\") \n            stop(gettextf(\"package %s was built before R 3.0.0: please re-install it\", \n                sQuote(pkgname)), call. = FALSE, domain = NA)\n        current <- getRversion()\n        if (length(Rdeps <- pkgInfo$Rdepends2)) {\n            for (dep in Rdeps) if (length(dep) > 1L) {\n                target <- dep$version\n                res <- do.call(dep$op, if (is.character(target)) \n                  list(as.numeric(R.version[[\"svn rev\"]]), as.numeric(sub(\"^r\", \n                    \"\", target)))\n                else list(current, as.numeric_version(target)))\n                if (!res) \n                  stop(gettextf(\"This is R %s, package %s needs %s %s\", \n                    current, sQuote(pkgname), dep$op, target), \n                    call. = FALSE, domain = NA)\n            }\n        }\n        if (R_version_built_under > current) \n            warning(gettextf(\"package %s was built under R version %s\", \n                sQuote(pkgname), as.character(built$R)), call. = FALSE, \n                domain = NA)\n        platform <- built$Platform\n        r_arch <- .Platform$r_arch\n        if (.Platform$OS.type == \"unix\") {\n        }\n        else {\n            if (nzchar(platform) && !grepl(\"mingw\", platform)) \n                stop(gettextf(\"package %s was built for %s\", \n                  sQuote(pkgname), platform), call. = FALSE, \n                  domain = NA)\n        }\n        if (nzchar(r_arch) && file.exists(file.path(pkgpath, \n            \"libs\")) && !file.exists(file.path(pkgpath, \"libs\", \n            r_arch))) \n            stop(gettextf(\"package %s is not installed for 'arch = %s'\", \n                sQuote(pkgname), r_arch), call. = FALSE, domain = NA)\n    }\n    checkNoGenerics <- function(env, pkg) {\n        nenv <- env\n        ns <- .getNamespace(as.name(pkg))\n        if (!is.null(ns)) \n            nenv <- asNamespace(ns)\n        if (exists(\".noGenerics\", envir = nenv, inherits = FALSE)) \n            TRUE\n        else {\n            !any(startsWith(names(env), \".__T\"))\n        }\n    }\n    checkConflicts <- function(package, pkgname, pkgpath, nogenerics, \n        env) {\n        dont.mind <- c(\"last.dump\", \"last.warning\", \".Last.value\", \n            \".Random.seed\", \".Last.lib\", \".onDetach\", \".packageName\", \n            \".noGenerics\", \".required\", \".no_S3_generics\", \".Depends\", \n            \".requireCachedGenerics\")\n        sp <- search()\n        lib.pos <- which(sp == pkgname)\n        ob <- names(as.environment(lib.pos))\n        if (!nogenerics) {\n            these <- ob[startsWith(ob, \".__T__\")]\n            gen <- gsub(\".__T__(.*):([^:]+)\", \"\\\\1\", these)\n            from <- gsub(\".__T__(.*):([^:]+)\", \"\\\\2\", these)\n            gen <- gen[from != package]\n            ob <- ob[!(ob %in% gen)]\n        }\n        ipos <- seq_along(sp)[-c(lib.pos, match(c(\"Autoloads\", \n            \"CheckExEnv\"), sp, 0L))]\n        cpos <- NULL\n        conflicts <- vector(\"list\", 0)\n        for (i in ipos) {\n            obj.same <- match(names(as.environment(i)), ob, nomatch = 0L)\n            if (any(obj.same > 0L)) {\n                same <- ob[obj.same]\n                same <- same[!(same %in% dont.mind)]\n                Classobjs <- which(startsWith(same, \".__\"))\n                if (length(Classobjs)) \n                  same <- same[-Classobjs]\n                same.isFn <- function(where) vapply(same, exists, \n                  NA, where = where, mode = \"function\", inherits = FALSE)\n                same <- same[same.isFn(i) == same.isFn(lib.pos)]\n                not.Ident <- function(ch, TRAFO = identity, ...) vapply(ch, \n                  function(.) !identical(TRAFO(get(., i)), TRAFO(get(., \n                    lib.pos)), ...), NA)\n                if (length(same)) \n                  same <- same[not.Ident(same)]\n                if (length(same) && identical(sp[i], \"package:base\")) \n                  same <- same[not.Ident(same, ignore.environment = TRUE)]\n                if (length(same)) {\n                  conflicts[[sp[i]]] <- same\n                  cpos[sp[i]] <- i\n                }\n            }\n        }\n        if (length(conflicts)) {\n            if (stopOnConflict) {\n                emsg <- \"\"\n                pkg <- names(conflicts)\n                notOK <- vector(\"list\", 0)\n                for (i in seq_along(conflicts)) {\n                  pkgname <- sub(\"^package:\", \"\", pkg[i])\n                  if (pkgname %in% canMaskEnv$canMask) \n                    next\n                  same <- conflicts[[i]]\n                  if (is.list(mask.ok)) \n                    myMaskOK <- mask.ok[[pkgname]]\n                  else myMaskOK <- mask.ok\n                  if (isTRUE(myMaskOK)) \n                    same <- NULL\n                  else if (is.character(myMaskOK)) \n                    same <- setdiff(same, myMaskOK)\n                  if (length(same)) {\n                    notOK[[pkg[i]]] <- same\n                    msg <- .maskedMsg(sort(same), pkg = sQuote(pkg[i]), \n                      by = cpos[i] < lib.pos)\n                    emsg <- paste(emsg, msg, sep = \"\\n\")\n                  }\n                }\n                if (length(notOK)) {\n                  msg <- gettextf(\"Conflicts attaching package %s:\\n%s\", \n                    sQuote(package), emsg)\n                  stop(errorCondition(msg, package = package, \n                    conflicts = conflicts, class = \"packageConflictError\"))\n                }\n            }\n            if (warn.conflicts) {\n                packageStartupMessage(gettextf(\"\\nAttaching package: %s\\n\", \n                  sQuote(package)), domain = NA)\n                pkg <- names(conflicts)\n                for (i in seq_along(conflicts)) {\n                  msg <- .maskedMsg(sort(conflicts[[i]]), pkg = sQuote(pkg[i]), \n                    by = cpos[i] < lib.pos)\n                  packageStartupMessage(msg, domain = NA)\n                }\n            }\n        }\n    }\n    if (verbose && quietly) \n        message(\"'verbose' and 'quietly' are both true; being verbose then ..\")\n    if (!missing(package)) {\n        if (is.null(lib.loc)) \n            lib.loc <- .libPaths()\n        lib.loc <- lib.loc[dir.exists(lib.loc)]\n        if (!character.only) \n            package <- as.character(substitute(package))\n        if (length(package) != 1L) \n            stop(\"'package' must be of length 1\")\n        if (is.na(package) || (package == \"\")) \n            stop(\"invalid package name\")\n        pkgname <- paste0(\"package:\", package)\n        newpackage <- is.na(match(pkgname, search()))\n        if (newpackage) {\n            pkgpath <- find.package(package, lib.loc, quiet = TRUE, \n                verbose = verbose)\n            if (length(pkgpath) == 0L) {\n                if (length(lib.loc) && !logical.return) \n                  stop(packageNotFoundError(package, lib.loc, \n                    sys.call()))\n                txt <- if (length(lib.loc)) \n                  gettextf(\"there is no package called %s\", sQuote(package))\n                else gettext(\"no library trees found in 'lib.loc'\")\n                if (logical.return) {\n                  if (!quietly) \n                    warning(txt, domain = NA)\n                  return(FALSE)\n                }\n                else stop(txt, domain = NA)\n            }\n            which.lib.loc <- normalizePath(dirname(pkgpath), \n                \"/\", TRUE)\n            pfile <- system.file(\"Meta\", \"package.rds\", package = package, \n                lib.loc = which.lib.loc)\n            if (!nzchar(pfile)) \n                stop(gettextf(\"%s is not a valid installed package\", \n                  sQuote(package)), domain = NA)\n            pkgInfo <- readRDS(pfile)\n            testRversion(pkgInfo, package, pkgpath)\n            if (is.character(pos)) {\n                npos <- match(pos, search())\n                if (is.na(npos)) {\n                  warning(gettextf(\"%s not found on search path, using pos = 2\", \n                    sQuote(pos)), domain = NA)\n                  pos <- 2\n                }\n                else pos <- npos\n            }\n            deps <- unique(names(pkgInfo$Depends))\n            depsOK <- isTRUE(conf.ctrl$depends.ok)\n            if (depsOK) {\n                canMaskEnv <- dynGet(\"__library_can_mask__\", \n                  NULL)\n                if (is.null(canMaskEnv)) {\n                  canMaskEnv <- new.env()\n                  canMaskEnv$canMask <- union(\"base\", conf.ctrl$can.mask)\n                  \"__library_can_mask__\" <- canMaskEnv\n                }\n                canMaskEnv$canMask <- unique(c(package, deps, \n                  canMaskEnv$canMask))\n            }\n            else canMaskEnv <- NULL\n            if (attach.required) \n                .getRequiredPackages2(pkgInfo, quietly = quietly)\n            cr <- conflictRules(package)\n            if (missing(mask.ok)) \n                mask.ok <- cr$mask.ok\n            if (missing(exclude)) \n                exclude <- cr$exclude\n            if (packageHasNamespace(package, which.lib.loc)) {\n                if (isNamespaceLoaded(package)) {\n                  newversion <- as.numeric_version(pkgInfo$DESCRIPTION[\"Version\"])\n                  oldversion <- as.numeric_version(getNamespaceVersion(package))\n                  if (newversion != oldversion) {\n                    tryCatch(unloadNamespace(package), error = function(e) {\n                      P <- if (!is.null(cc <- conditionCall(e))) \n                        paste(\"Error in\", deparse(cc)[1L], \": \")\n                      else \"Error : \"\n                      stop(gettextf(\"Package %s version %s cannot be unloaded:\\n %s\", \n                        sQuote(package), oldversion, paste0(P, \n                          conditionMessage(e), \"\\n\")), domain = NA)\n                    })\n                  }\n                }\n                tt <- tryCatch({\n                  attr(package, \"LibPath\") <- which.lib.loc\n                  ns <- loadNamespace(package, lib.loc)\n                  env <- attachNamespace(ns, pos = pos, deps, \n                    exclude, include.only)\n                }, error = function(e) {\n                  P <- if (!is.null(cc <- conditionCall(e))) \n                    paste(\" in\", deparse(cc)[1L])\n                  else \"\"\n                  msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", \n                    sQuote(package), P, conditionMessage(e))\n                  if (logical.return && !quietly) \n                    message(paste(\"Error:\", msg), domain = NA)\n                  else stop(msg, call. = FALSE, domain = NA)\n                })\n                if (logical.return && is.null(tt)) \n                  return(FALSE)\n                attr(package, \"LibPath\") <- NULL\n                {\n                  on.exit(detach(pos = pos))\n                  nogenerics <- !.isMethodsDispatchOn() || checkNoGenerics(env, \n                    package)\n                  if (isFALSE(conf.ctrl$generics.ok) || (stopOnConflict && \n                    !isTRUE(conf.ctrl$generics.ok))) \n                    nogenerics <- TRUE\n                  if (stopOnConflict || (warn.conflicts && !exists(\".conflicts.OK\", \n                    envir = env, inherits = FALSE))) \n                    checkConflicts(package, pkgname, pkgpath, \n                      nogenerics, ns)\n                  on.exit()\n                  if (logical.return) \n                    return(TRUE)\n                  else return(invisible(.packages()))\n                }\n            }\n            else stop(gettextf(\"package %s does not have a namespace and should be re-installed\", \n                sQuote(package)), domain = NA)\n        }\n        if (verbose && !newpackage) \n            warning(gettextf(\"package %s already present in search()\", \n                sQuote(package)), domain = NA)\n    }\n    else if (!missing(help)) {\n        if (!character.only) \n            help <- as.character(substitute(help))\n        pkgName <- help[1L]\n        pkgPath <- find.package(pkgName, lib.loc, verbose = verbose)\n        docFiles <- c(file.path(pkgPath, \"Meta\", \"package.rds\"), \n            file.path(pkgPath, \"INDEX\"))\n        if (file.exists(vignetteIndexRDS <- file.path(pkgPath, \n            \"Meta\", \"vignette.rds\"))) \n            docFiles <- c(docFiles, vignetteIndexRDS)\n        pkgInfo <- vector(\"list\", 3L)\n        readDocFile <- function(f) {\n            if (basename(f) %in% \"package.rds\") {\n                txt <- readRDS(f)$DESCRIPTION\n                if (\"Encoding\" %in% names(txt)) {\n                  to <- if (Sys.getlocale(\"LC_CTYPE\") == \"C\") \n                    \"ASCII//TRANSLIT\"\n                  else \"\"\n                  tmp <- try(iconv(txt, from = txt[\"Encoding\"], \n                    to = to))\n                  if (!inherits(tmp, \"try-error\")) \n                    txt <- tmp\n                  else warning(\"'DESCRIPTION' has an 'Encoding' field and re-encoding is not possible\", \n                    call. = FALSE)\n                }\n                nm <- paste0(names(txt), \":\")\n                formatDL(nm, txt, indent = max(nchar(nm, \"w\")) + \n                  3L)\n            }\n            else if (basename(f) %in% \"vignette.rds\") {\n                txt <- readRDS(f)\n                if (is.data.frame(txt) && nrow(txt)) \n                  cbind(basename(gsub(\"\\\\.[[:alpha:]]+$\", \"\", \n                    txt$File)), paste(txt$Title, paste0(rep.int(\"(source\", \n                    NROW(txt)), ifelse(nzchar(txt$PDF), \", pdf\", \n                    \"\"), \")\")))\n                else NULL\n            }\n            else readLines(f)\n        }\n        for (i in which(file.exists(docFiles))) pkgInfo[[i]] <- readDocFile(docFiles[i])\n        y <- list(name = pkgName, path = pkgPath, info = pkgInfo)\n        class(y) <- \"packageInfo\"\n        return(y)\n    }\n    else {\n        if (is.null(lib.loc)) \n            lib.loc <- .libPaths()\n        db <- matrix(character(), nrow = 0L, ncol = 3L)\n        nopkgs <- character()\n        for (lib in lib.loc) {\n            a <- .packages(all.available = TRUE, lib.loc = lib)\n            for (i in sort(a)) {\n                file <- system.file(\"Meta\", \"package.rds\", package = i, \n                  lib.loc = lib)\n                title <- if (nzchar(file)) {\n                  txt <- readRDS(file)\n                  if (is.list(txt)) \n                    txt <- txt$DESCRIPTION\n                  if (\"Encoding\" %in% names(txt)) {\n                    to <- if (Sys.getlocale(\"LC_CTYPE\") == \"C\") \n                      \"ASCII//TRANSLIT\"\n                    else \"\"\n                    tmp <- try(iconv(txt, txt[\"Encoding\"], to, \n                      \"?\"))\n                    if (!inherits(tmp, \"try-error\")) \n                      txt <- tmp\n                    else warning(\"'DESCRIPTION' has an 'Encoding' field and re-encoding is not possible\", \n                      call. = FALSE)\n                  }\n                  txt[\"Title\"]\n                }\n                else NA\n                if (is.na(title)) \n                  title <- \" ** No title available ** \"\n                db <- rbind(db, cbind(i, lib, title))\n            }\n            if (length(a) == 0L) \n                nopkgs <- c(nopkgs, lib)\n        }\n        dimnames(db) <- list(NULL, c(\"Package\", \"LibPath\", \"Title\"))\n        if (length(nopkgs) && !missing(lib.loc)) {\n            pkglist <- paste(sQuote(nopkgs), collapse = \", \")\n            msg <- sprintf(ngettext(length(nopkgs), \"library %s contains no packages\", \n                \"libraries %s contain no packages\"), pkglist)\n            warning(msg, domain = NA)\n        }\n        y <- list(header = NULL, results = db, footer = NULL)\n        class(y) <- \"libraryIQR\"\n        return(y)\n    }\n    if (logical.return) \n        TRUE\n    else invisible(.packages())\n}\n<bytecode: 0x129163a58>\n<environment: namespace:base>\n\ndescriptive<-read_excel(\"descriptive_stat.xlsx\")\nprovincedata<-read_excel(\"province.xlsx\")\noptions(scipen=999)\n\n\nbp <- barplot(descriptive$total_pollutants, names.arg =descriptive$year, main = \"Total amount of pollutants\",col=\"lightcyan\",cex.names=0.7,)\n\n\n\ntext(x=bp, y=descriptive$total_pollutants*0.9,labels = descriptive$total_pollutants,col=\"red\",cex=0.7)\n\n\n\nbp1 <- barplot(descriptive$emission, names.arg =descriptive$year, main = \"Total amount of emission\",col=\"lightcyan\",cex.names=0.7,)\n\n\n\ntext(x=bp, y=descriptive$emission*0.9,labels = descriptive$emission,col=\"red\",cex=0.7)\n\n\n\nbp2 <- barplot(descriptive$landfill, names.arg =descriptive$year, main = \"Total amount of landfill\",col=\"lightcyan\",cex.names=0.7,)\n\n\n\ntext(x=bp, y=descriptive$landfill*0.9,labels = descriptive$landfill,col=\"red\",cex=0.7)\n\n\n\nbp3 <- barplot(descriptive$transfer, names.arg =descriptive$year, main = \"Total amount of transfer\",col=\"lightcyan\",cex.names=0.7,)\n\n\n\ntext(x=bp, y=descriptive$transfer*0.9,labels = descriptive$transfer,col=\"red\",cex=0.7)\n\n\n\nbp4 <- barplot(descriptive$report_company, names.arg =descriptive$year, main = \"The number of companies reporting\",col=\"lightcyan\",cex.names=0.7,)\n\n\n\ntext(x=bp, y=descriptive$report_company*0.9,labels = descriptive$report_company,col=\"red\",cex=0.7)\n\n\n\nggplot(provincedata, aes(x=\"\", y=total_pollutants, fill = province))+\n  geom_bar(width = 0.5, stat = \"identity\", color = \"white\") +\n  coord_polar(\"y\", start=0)+\n  geom_text(aes(label = paste0(round(total_pollutants/10079236016*100,1),\"%\")),\n            position = position_stack(vjust = 0.5), color = \"#ffffff\")+\n  theme_void()+\n  scale_fill_manual(values =c(\"#FF0000FF\", \"#FF9900FF\", \"#00FF00FF\", \"#6699FFFF\", \"#CC33FFFF\", \"#99991EFF\", \"#999999FF\", \"#FF00CCFF\", \"358000FF\", \"#0000CCFF\", \"#996600FF\", \"#666666FF\", \"#79CC3DFF\", \"#CCCC99FF\", \"#CC0000FF\", \"#CC99FFFF\", \"#FFCCCCFF\"))"
  },
  {
    "objectID": "assignment5.html",
    "href": "assignment5.html",
    "title": "Assignment 5",
    "section": "",
    "text": "More on creating charts\na.No applications like Tableau or Excel can be used.\nb.Codes and products posted on own GitHub website/page\nc.Class members may consult with each other but embellish own final data visualization products.\nd.Charts for this week: 3-5in Chart thought starter\n\n\n# Clear environment\nrm(list=ls())               \n\nlibrary(ggplot2)\nlibrary(fmsb)\n\ndata01 <- data.frame(\n  Year=c(\"1y\", \"1y\", \"2y\", \"2y\", \"3y\", \"3y\", \"4y\", \"4y\", \"5y\", \"5y\"), \n  policy=c(\"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\"),\n  effect=c(13, 14, 15, 11, 16, 15, 17, 18, 18, 12)\n)\n\nggplot(data01, aes(x = Year, y = effect, fill = policy)) +\n  geom_col(position = position_dodge()) +\n  scale_fill_manual(values = c(\"#f7001d\", \"#0099f7\")) +\n  coord_flip()\n\n\n\nggplot(data01, aes(x = Year, y = effect, fill = policy)) +\n  geom_col(position = position_dodge()) +\n  scale_fill_manual(values = c(\"#f7001d\", \"#0099f7\")) +\n  geom_text(aes(label = effect), position = position_dodge(0.5), vjust = 1, size = 3, color = \"#ffffff\")\n\n\n\ndata02 <- as.data.frame(matrix(\n  c(13, 14, 15, 11, 16, 15, 17, 18, 18, 12) , ncol=5))\ncolnames(data02) <- \n  c(\"1year\", \"2year\", \"3year\", \"4year\", \"5year\")\nrownames(data02) <- c(\"A\", \"B\")\ndata02 <- rbind(rep(20,5) , rep(0,5) , data02)\n\ncolors_border=c(rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9), rgb(0.7,0.5,0.1,0.9))\n\ncolors_in=c(rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4), rgb(0.7,0.5,0.1,0.4))\n\nradarchart(data02 , axistype=1, \n            title = \"Comparison of the effect between A and B\",\n            pcol=colors_border, pfcol=colors_in, \n            plwd=4 , plty=1, cglcol=\"grey\", cglty=1, \n            axislabcol=\"grey\", caxislabels=seq(0,20,5), \n            cglwd=0.8, vlcex=0.8 \n)"
  },
  {
    "objectID": "assignment4.html",
    "href": "assignment4.html",
    "title": "Assignment 4",
    "section": "",
    "text": "# Data Visualization\n# Assignment 4-1\n\n# Set Column Names\ndf <- data.frame(x = c(\"Texas\", \"Florida\", \"NewYork\",\n     \"California\"), width = c(25, 50, 75, 100), height = c(100,\n     75, 50, 25))\n\ndf$w <- cumsum(df$width)\ndf$wm <- df$w - df$width\ndf$wt <- with(df, wm + (w - wm)/2)\n\nlibrary(ggplot2)\np <- ggplot(df, aes(ymin = 0))\n\np1 <- p + geom_rect(aes(xmin = wm, xmax = w,\n     ymax = height, fill = x))\n\np2 <- p1 + geom_text(aes(x = wt, y = height *\n     0.5, label = x))\n\np2 + ggtitle(\"Carbon Emission and Gas Price by State\") + xlab(\"Gas Price\") + ylab(\"Carbon Emission\")\n\n\n\n\nThe figure above shows the relationship between carbon emissions and gas prices by state. California has the highest gas price and the least carbon emission. On the other hand, Texas has the least gas price while the highest carbon emission. The figure illustrates that the higher the gas price, the lower the carbon emissions."
  },
  {
    "objectID": "assignment4.html#table-with-embedded-charts",
    "href": "assignment4.html#table-with-embedded-charts",
    "title": "Assignment 4",
    "section": "2. Table with Embedded Charts",
    "text": "2. Table with Embedded Charts\n\n# Data Visualization\n# Assignment 4-2\n\n# Creating Table with Embedded Charts\ncarbon <- read.csv(\"carbon.csv\", header=TRUE)\nhead(carbon)\n\n       State PerCapitaEmission CarbonIntensity Region           Division\n1    Alabama         21.648482        433.6878   West            Pacific\n2     Alaska         46.674987        643.1302  South East South Central\n3    Arizona         12.690212        239.3805  South West South Central\n4   Arkansas         21.539954        500.0933   West           Mountain\n5 California          9.081707        140.3001   West            Pacific\n6   Colorado         15.930418        263.3013   West           Mountain\n\nlibrary(Hmisc)\n\nLoading required package: lattice\n\n\nLoading required package: survival\n\n\nLoading required package: Formula\n\n\n\nAttaching package: 'Hmisc'\n\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n✔ purrr   0.3.5      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()    masks stats::filter()\n✖ dplyr::lag()       masks stats::lag()\n✖ dplyr::src()       masks Hmisc::src()\n✖ dplyr::summarize() masks Hmisc::summarize()\n\nlibrary(ggplot2)\n\n# Calucating Mean\nmean(carbon$PerCapitaEmission)\n\n[1] 20.29298\n\n\n\n# Creating Dummy Variable\ncarbon$PerCapitaEmission_dummy <- ifelse(carbon$PerCapitaEmission>=20.20489, 1, 0)\n\n# Creating Ordinal Variable\ncarbon$CarbonIntensity_ordinal <- cut2(carbon$CarbonIntensity, m=10)\n\n# \ntable(carbon$PerCapitaEmission_dummy, carbon$CarbonIntensity_ordinal)\n\n   \n    [ 71.2, 197) [196.6, 270) [269.6, 342) [342.4, 500) [500.1,1035]\n  0           11           10           10            3            0\n  1            0            0            0            7           10\n\n\n\ncarbon_df <- data.frame(carbon)\n\n# Code below does not work... \n## p <- ggplot2(carbon_df,aes(CarbonIntensity_ordinal,PerCapitaEmission,fill=as.factor(Division)),size=5)+geom_bar(position=\"dodge\",stat=\"identity\")+facet_wrap(~CarbonIntensity_ordinad,nrow=4)"
  },
  {
    "objectID": "assignment10.html",
    "href": "assignment10.html",
    "title": "Assignment 8",
    "section": "",
    "text": "Assignment 8"
  },
  {
    "objectID": "Final.html",
    "href": "Final.html",
    "title": "Final Project",
    "section": "",
    "text": "# EPPS 6356 - Data Visualization\n# Pyung Kim\n\nrm(list=ls())\n\n# 1. Data Setting\nsetwd(\"/Users/pyungkim/Downloads/02_2022 Fall/03_Data Visualization/Final/Mapping Data/\")\nload(\"/Users/pyungkim/Downloads/02_2022 Fall/03_Data Visualization/Final/Mapping Data/toxic.rdata\")\nlibrary(sf)    # install.packages(\"sf\") \n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n# 2. Load Seoul grid data (shp file)\ngrid <- st_read(\"/Users/pyungkim/Downloads/02_2022 Fall/03_Data Visualization/Final/Mapping Data/sigun_grid/seoul.shp\")  \n\nReading layer `seoul' from data source \n  `/Users/pyungkim/Downloads/02_2022 Fall/03_Data Visualization/Final/Mapping Data/sigun_grid/seoul.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 694 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 126.7645 ymin: 37.42899 xmax: 127.1835 ymax: 37.70146\nGeodetic CRS:  GCS_unknown\n\nemission <-st_join(emission, grid, join = st_intersects)\n\n\n# 3. Calculate average emission by grid in Seuol, South Korea \nkde_high <- aggregate(emission$py, by=list(emission$ID), mean)\ncolnames(kde_high) <- c(\"ID\", \"avg_emission\")   # Change column names\n\n\n# 4. Merge GRID and Average Emission\nkde_high <- merge(grid, kde_high,  by=\"ID\")   # Merge by ID\nlibrary(ggplot2) # install.packages(\"ggplot2\")\nlibrary(dplyr)   # install.packages(\"dplyr\")\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# 5. Emission map by grid in Seoul\nkde_high %>% ggplot(aes(fill = avg_emission)) + \n  geom_sf() + \n  scale_fill_gradient(low = \"white\", high = \"red\")\n\n\n\n#################################################################\n\n# 6. Change \"sf\" to \"sf\"\n## sf is dataframe. so, it is easy to calculate.\n## sp is shape, which is easy to create maps\n\nlibrary(sp) # install.packages(\"sp\")\nkde_high_sp <- as(st_geometry(kde_high), \"Spatial\")    # sf => sp\n\n\n# 7. Set corners to draw maps\nx <- coordinates(kde_high_sp)[,1]\ny <- coordinates(kde_high_sp)[,2] \n\nl1 <- bbox(kde_high_sp)[1,1] - (bbox(kde_high_sp)[1,1]*0.0001)\nl2 <- bbox(kde_high_sp)[1,2] + (bbox(kde_high_sp)[1,2]*0.0001)\nl3 <- bbox(kde_high_sp)[2,1] - (bbox(kde_high_sp)[2,1]*0.0001)\nl4 <- bbox(kde_high_sp)[2,2] + (bbox(kde_high_sp)[1,1]*0.0001)\n\n# 8. Draw windows\nlibrary(spatstat)  # install.packages(\"spatstat\")\n\nLoading required package: spatstat.data\n\n\nLoading required package: spatstat.geom\n\n\nspatstat.geom 3.0-3\n\n\nLoading required package: spatstat.random\n\n\nspatstat.random 3.0-1\n\n\nLoading required package: spatstat.explore\n\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nspatstat.explore 3.0-5\n\n\nLoading required package: spatstat.model\n\n\nLoading required package: rpart\n\n\nspatstat.model 3.0-2\n\n\nLoading required package: spatstat.linnet\n\n\nspatstat.linnet 3.0-3\n\n\n\nspatstat 3.0-2 \nFor an introduction to spatstat, type 'beginner' \n\nwin <- owin(xrange=c(l1,l2), yrange=c(l3,l4)) # Create window\nplot(win)         # Check Boundaries\n\n\n\nrm(list = c(\"kde_high_sp\", \"apt_emission\", \"l1\", \"l2\", \"l3\", \"l4\")) # Clean variables\n\nWarning in rm(list = c(\"kde_high_sp\", \"apt_emission\", \"l1\", \"l2\", \"l3\", : object\n'apt_emission' not found\n\n# 9. Draw density Graph\np <- ppp(x, y, window=win) # Create coordinates on the window\nd <- density.ppp(p, weights=kde_high$avg_emission, # Change by kernel density function\n                 sigma = bw.diggle(p), \n                 kernel = 'gaussian')  \nplot(d)\n\n\n\nrm(list = c(\"x\", \"y\", \"win\",\"p\")) # Clean variables\n\n# 10. Raster Map (below explanation on KDE came from Wikipedia)\n## In statistics, kernel density estimation (KDE) is the application of kernel smoothing for probability density estimation, \n## i.e., a non-parametric method to estimate the probability density function of a random variable based on kernels as weights. \n## KDE answers a fundamental data smoothing problem where inferences about the population are made, based on a finite data sample. \n## In some fields such as signal processing and econometrics it is also termed the Parzen???Rosenblatt window method, \n## after Emanuel Parzen and Murray Rosenblatt, who are usually credited with independently creating it in its current form.\n## One of the famous applications of kernel density estimation is in estimating the class-conditional marginal densities of data when using a naive Bayes classifier,\n## which can improve its prediction accuracy.\n\nd[d < quantile(d)[4] + (quantile(d)[4]*0.1)] <- NA   # Erase Noise\nlibrary(raster)      #  install.packages(\"raster\")\n\n\nAttaching package: 'raster'\n\n\nThe following object is masked from 'package:nlme':\n\n    getData\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nraster_high <- raster(d)  # Change by raster\nplot(raster_high)\n\n\n\n# 11. Map grooming\n## Load Seoul shp file\nbnd <- st_read(\"/Users/pyungkim/Downloads/02_2022 Fall/03_Data Visualization/Final/Mapping Data/sigun_bnd/seoul.shp\")\n\nReading layer `seoul' from data source \n  `/Users/pyungkim/Downloads/02_2022 Fall/03_Data Visualization/Final/Mapping Data/sigun_bnd/seoul.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 126.7645 ymin: 37.42899 xmax: 127.1835 ymax: 37.70146\nGeodetic CRS:  GCS_unknown\n\nraster_high <- crop(raster_high, extent(bnd))      # Crop unnecessaries\ncrs(raster_high) <- sp::CRS(\"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 + towgs84=0,0,0\") # Define coordinates\nplot(raster_high)\nplot(bnd, col=NA, border = \"red\", add=TRUE)\n\n\n\n## 12. Put raster on the map\nlibrary(rgdal)    # install.packages(\"rgdal\")\n\nPlease note that rgdal will be retired during 2023,\nplan transition to sf/stars/terra functions using GDAL and PROJ\nat your earliest convenience.\nSee https://r-spatial.org/r/2022/04/12/evolution.html and https://github.com/r-spatial/evolution\nrgdal: version: 1.6-2, (SVN revision 1183)\nGeospatial Data Abstraction Library extensions to R successfully loaded\nLoaded GDAL runtime: GDAL 3.5.3, released 2022/10/21\nPath to GDAL shared files: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library/rgdal/gdal\n GDAL does not use iconv for recoding strings.\nGDAL binary built with GEOS: TRUE \nLoaded PROJ runtime: Rel. 9.1.0, September 1st, 2022, [PJ_VERSION: 910]\nPath to PROJ shared files: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library/rgdal/proj\nPROJ CDN enabled: FALSE\nLinking to sp version:1.5-1\nTo mute warnings of possible GDAL/OSR exportToProj4() degradation,\nuse options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal.\n\nlibrary(leaflet)  # install.packages(\"leaflet\")\nleaflet() %>% \n  #Base Map\n  addProviderTiles(providers$CartoDB.Positron) %>% \n  #Call Boundaries\n  addPolygons(data = bnd, weight = 3, color= \"red\", fill = NA) %>% \n  #Add Raster Map\n  addRasterImage(raster_high, \n                 colors = colorNumeric(c(\"blue\", \"green\",\"yellow\",\"red\"), \n                                       values(raster_high), na.color = \"transparent\"), opacity = 0.4) \n\n\n\n\n# Save\n# save(raster_high, file=\"/Users/pyungkim/Downloads/02_2022 Fall/03_Data Visualization/Final/Mapping Data//kde_high.rdata\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pyung Kim",
    "section": "",
    "text": "Research Interests\n\nHealth Policy\nClimate Policy\nGIS and Spatial Epidemiology\nEconometrics and Machine Learning\n\n\n\n\n\n\nContact Me\npyung.kim@utdallas.edu\nGoogle Scholar\nLinkedin"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Education\n\nDoctoral Student in Public Policy, 2021 - Current\n\nThe University of Texas at Dallas\nBrain Berry J.L. Scholar\n\nMaster’s in Public Administration, 2020\n\nYonsei University\nThesis: The Effect of Carbon Pricing – Evidence from the Korean Emission Trading Scheme\nCommittee: Hyonhoe Bae (Chair), Taejun Lah, Sounman Hong\nBrain Korea 21 PLUS Scholar\n\nBachelor’s in Public Administration, 2018\n\nAjou University\nGraduate with Summa Cum Laude\nThe Next Century Humanities Scholar\n\nExchange Student, Sept 2016 - Aug 2017\n\nJulius-Maximilians University of Wuerzburg, Germany\n\n\n\n\n\n\n\nScholarships\n\nBrain Berry J.L. Scholarship\n\nFunded by University of Texas at Dallas\nNamed in honor of Brian J.L. Berry, a member of the National Academy of Sciences\nAdditional stipends (Aug 2021 – Aug 2026, expected 5 years)\n\nUTD Graduate Studies\n\nFunded by University of Texas at Dallas\nScholarship and stipends (Aug 2021 – Aug 2026, expected 5 years)\n\nBrain Korea 21 PLUS Scholarship\n\nFunded by National Research Foundation\nNationally competitive scholarship supporting graduates\nStipends (Mar 2018 – Feb 2020, 2 years)\n\nYUPA Graduate Studies Scholarship\n\nFunded by Yonsei University\nScholarship (Mar 2018 – Feb 2020, 2 yrs)\n\nThe Next Century Humanities Scholarship\n\nFunded by Korea Ministry of Education\nNationally competitive scholarship supporting undergraduates in social sciences\nScholarship and stipends (Mar 2015 – Feb 2018, 3 years)\n\nTeaching Assistantship\n\nFunded by Ajou University\nStipends (Sept 2014 – Aug 2016, 2 years)\n\nMerit-based Scholarship\n\nFunded by Ajou University\nScholarship (Sept 2014 – Aug 2016, 1 semester)\n\n\n\n\n\n\n\nHonors and Awards\n\nSumma Cum Laude, Ajou University, 2018\nExcellence Award in Undergraduate Research Project, Ajou University, 2015\nDean’s list, Ajou University, 2015\nDean’s list, Ajou University, 2014\n\n\n\n\n\n\nVolunteers\n\nGraduate Student Association (Vice President)\n\nDepartment of Public Administration at Yonsei University\n\nStudent Ambassadors\n\nThe Admission Office at Ajou University"
  },
  {
    "objectID": "assignment9.html",
    "href": "assignment9.html",
    "title": "Assignment 9",
    "section": "",
    "text": "Assignment 9"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Geospatial Community Mapping to Assess Social and Environmental Barriers and Facilitators for Burn Survivors\nFunded by National Institute on Disability, Independent Living, and Rehabilitation Research (Nov 2022 - Current)\n“A Study on International Standards of SW Safety Assessment and Legal Arrangement of Domestic and Foreign Countries”\nFunded by Software Policy & Research Institute under the Korea Ministry of Science and ICT (Aug 2020 – Nov 2020)\n“An Analysis of the Local Government Social Welfare Budget”\nFunded by Korea Ministry of Health and Welfare (Jul 2018 – Aug 2018)\n“Analysis of national distrust structure of nuclear safety regulations and development of risk communication strategies for recovering trust”\nFunded by Korea Foundation of Nuclear Safety (Mar 2016 -- Aug 2016)\n\n\n\n“Track and analyze the performance of technological development project for original research”\nFunded by National Research Foundation of Korea (Jul 2015 – Aug 2015)\n\n\n\n“Analysis of national distrust structure of nuclear safety regulations and development of risk communication strategies for recovering trust”\nFunded by Korea Foundation of Nuclear Safety (Jan 2015 -- Aug 2015)"
  }
]